\documentclass{beamer}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{url}
\usepackage{listings}
\usepackage{adjustbox}
\usepackage{chronology}
\usepackage{algpseudocode}
\usepackage{algorithm}


% \usepackage{sfmath}
%\usepackage{lxfonts}
%\usepackage{mathdesign}
\usepackage{unicode-math}

% Graphics
\usepackage{graphicx}
%\usepackage{tikz}
%\usetikzlibrary{matrix, calc, arrows, snakes}

% Figures
\usepackage{caption}
\captionsetup{labelformat=empty,labelsep=none}

% Font
\usepackage{microtype}
%\usepackage[scaled]{beramono}
\usepackage{fontspec,xunicode}
\newfontfamily\sbmyriad{Myriad Pro Semibold}
\setsansfont{Myriad Pro}
\setmonofont{Myriad Pro}
\setbeamerfont{title}{family=\sbmyriad}
\setbeamerfont{frametitle}{family=\bf}


% Beamer theme settings
\usecolortheme{seagull}
\setbeamertemplate{itemize item}{\raisebox{0.8mm}{\rule{1.2mm}{1.2mm}}}
\usenavigationsymbolstemplate{} % no navigation buttons


\title{Master's thesis defence}
\subtitle{Option pricing using functional data-parallel languages}
\author{Philip Carlsen \and Martin Dybdal}
\date{22. March 2013}
\institute{Computer Science\\
University of Copenhagen}




% ADD "parfor" to algorithmic environment
  % declaration of the new block
  \algblock{ParFor}{EndParFor}
  % customising the new block
  \algnewcommand\algorithmicparfor{\textbf{parfor}}
  \algnewcommand\algorithmicpardo{\textbf{do}}
  \algnewcommand\algorithmicendparfor{\textbf{end\ parfor}}
  \algrenewtext{ParFor}[1]{\algorithmicparfor\ #1\ \algorithmicpardo}
  \algrenewtext{EndParFor}{\algorithmicendparfor}


% Bitwise and and or operators
% http://tex.stackexchange.com/questions/39313/double-nested-logical-and-and-logical-or-symbols
\DeclareFontFamily{U}{matha}{\hyphenchar\font45}
\DeclareFontShape{U}{matha}{m}{n}{
      <5> <6> <7> <8> <9> <10> gen * matha
      <10.95> matha10 <12> <14.4> <17.28> <20.74> <24.88> matha12
      }{}

\newcommand{\bland}{\mathbin{
  \raisebox{.1ex}{%
    \rotatebox[origin=c]{-90}{\usefont{U}{matha}{m}{n}\symbol{\string"CE}}}}}
\newcommand{\blor}{\mathbin{
  \raisebox{.1ex}{%
    \rotatebox[origin=c]{90}{\usefont{U}{matha}{m}{n}\symbol{\string"CE}}}}}





\begin{document}
% Welcome
% Both a defence and this is what I do
\frame{\titlepage}

% % Nice diagram showing how the talk will progress
% \begin{frame}
%   \frametitle{Agenda}
%   \tableofcontents
% \end{frame}

\begin{frame}
  \frametitle{GPU Applications: Finance}
  \begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphics/finance.jpg}
%    \caption{Option pricing}
\label{fig:gpufinance}
\end{figure}
\end{frame}
\begin{frame}
  \frametitle{GPU Applications: Bioinformatics}
  \begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{graphics/fah_clientGeForce9600GT.png}
    \caption{Protein Folding}
\label{fig:foldingathome}
\end{figure}


  % \begin{itemize}
  % \item Computer vision
  % \item Scientific simulation (e.g. engineering, chemistry, physics)
  % \item Finance
  % \end{itemize}
\end{frame} 

\begin{frame}
  \frametitle{GPU Applications: Physics simulations}
  \begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{graphics/opencl_nbody.jpg}
    \caption{N-body simulation}
\label{fig:simulation}
\end{figure}

\end{frame}
\begin{frame}
  \frametitle{GPU Applications: Medical imaging}

\end{frame}


\begin{frame}[t]
  \frametitle{GPUs vs. CPUs}
  \vspace{0.5cm}
   \begin{minipage}[t]{0.40\linewidth}
    NVIDIA GK104 GPU\\
    Multiprocessor\vspace{0.15cm}\\
    \includegraphics[width=0.8\textwidth]{graphics/nvidia_kepler_gk104_sm.pdf}
    % \begin{itemize}
    % \item 3540 mio. transistors
    % \item 1536 cores
    % \item Small caches
    % \item Many compute units
    % \item Optimized for throughput
    % \end{itemize}
  \end{minipage}
%  \pause
  \begin{minipage}[t]{0.55\linewidth}
    Intel Ivy Bridge CPU\vspace{0.15cm}\\
    \includegraphics[width=\textwidth]{graphics/Intel-3rd-Generation-Ivy-Bridge-Processor.jpg}
    \begin{itemize}
    \item<1|only@1> Computation vs. Caching
    \item<1|only@1> SIMD vs. SISD
    \item<1|only@1> Throughput vs. latency
    \item<2-> Memory access coordination
    \item<3-> Avoid memory accesses\\ $\Rightarrow$ program fusion
    \item<4-> Schedule enough work
    \end{itemize}
  \end{minipage}
\end{frame}

% \begin{frame}
%   \frametitle{GPU programming concepts}
%   \begin{itemize}
%   \item Memory accesses are expensive
%   \item Coordination through memory coalescing
%   \item Compute on any single data item for as long as possible
%   \item Fusion
%   \item (Synchronization)
%   \item (SMs and blocks)
%   \end{itemize}
% \end{frame}

\begin{frame}
  \frametitle{GPU programming languages}

What we want:
  \begin{itemize}
  \item Avoid manual memory management
  \item Avoid manual fusion
  \item Fusion with library code
  \item Good abstractions
  \item Hardware independent
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Option styles}
\begin{adjustbox}{minipage=0.9\textwidth,center}
    \vspace{-4mm}
    \begin{chronology}[5]{2013}{2040}{3ex}{\textwidth}
      \event{2013}{now} \event{\decimaldate{1}{1}{2040}}{expiry}
    \end{chronology}\\
    European option

    \pause \vspace{7mm}
    \begin{chronology}[5]{2013}{2040}{3ex}{\textwidth}
      \event{2013}{now}
      \event[2020]{\decimaldate{1}{1}{2040}}{exercise time}
      \event{\decimaldate{1}{1}{2040}}{expiry}
    \end{chronology}
    American option

    \pause \vspace{7mm}
    \begin{chronology}[5]{2013}{2040}{3ex}{\textwidth}
      \event{2013}{now} \event{\decimaldate{1}{1}{2020}}{exercise
        time} \event{\decimaldate{1}{1}{2025}}{exercise time}
      \event{\decimaldate{1}{1}{2030}}{exercise time}
      \event{\decimaldate{1}{1}{2035}}{exercise time}
      \event{\decimaldate{1}{1}{2040}}{expiry}
    \end{chronology}
    Bermudan option
\end{adjustbox}

\end{frame}

% \fbox{  \begin{tikzpicture}
%     \node [] (now) at (0,0) {\rotatebox{-45}{\emph{now}}};
%     \node (expiry) at (8,0) {\rotatebox{-45}{\emph{expiry}}};
%     \draw[->,gray] (now) edge (expiry);

%     %\draw[->,gray,rounded corners] node[text=black,pos=.7]
% %    (now) -- (expiry);
%   \end{tikzpicture}
% }


% \begin{tikzpicture}[snake=zigzag, line before snake = 5mm, line after snake = 5mm]
% %draw horizontal line   
% \draw (0,0) -- (2,0);
% \draw[snake] (2,0) -- (4,0);
% \draw (4,0) -- (5,0);
% \draw[snake] (5,0) -- (7,0);

% %draw vertical lines
% \foreach \x in {0,1,2,4,5,7}
%    \draw (\x cm,3pt) -- (\x cm,-3pt);

% %draw nodes
% \draw (0,0) node[below=3pt] {$ 0 $} node[above=3pt] {$   $};
% \draw (1,0) node[below=3pt] {$ 1 $} node[above=3pt] {$ 10 $};
% \draw (2,0) node[below=3pt] {$ 2 $} node[above=3pt] {$ 20 $};
% \draw (3,0) node[below=3pt] {$  $} node[above=3pt] {$  $};
% \draw (4,0) node[below=3pt] {$ 5 $} node[above=3pt] {$ 50 $};
% \draw (5,0) node[below=3pt] {$ 6 $} node[above=3pt] {$ 60 $};
% \draw (6,0) node[below=3pt] {$  $} node[above=3pt] {$  $};
% \draw (7,0) node[below=3pt] {$ n $} node[above=3pt] {$ 10n $};
% \end{tikzpicture}

  % \begin{itemize}
  % \item Define american options
  % \item Binomial pricing
  % \item LSM
  % \item Sobol-sequence for sampling LSM paths
  % \end{itemize}


\begin{frame}
  \frametitle{Option pricing: Binomial method}
$$S(t+\Delta t) = \left\{
  \begin{array}{ll}
    S(t)u & \quad \text{with probability $q$} \\
    S(t)d & \quad \text{with probability $1-q$}
  \end{array} \right.
$$

\begin{figure}
  \centering
  \tikzstyle{nodestyle} = [text centered, minimum size=0.42cm, inner sep=0]

\begin{tikzpicture}
  \node at (0,0) [nodestyle] (S1) {$S(t_0)$};

  \node at (-1, -1) [nodestyle] (dS) {$dS(t_0)$};
  \node at ( 1, -1) [nodestyle] (uS) {$uS(t_0)$};

  \node at ( 2, -2) [nodestyle] (u2S) {$u^2S(t_0)$};
  \node at ( 0, -2) [nodestyle] (S2) {$S(t_0)$};
  \node at (-2, -2) [nodestyle] (d2S) {$d^2S(t_0)$};

  \node at ( 3, -3) [nodestyle] (u3S) {$u^3S(t_0)$};
  \node at ( 1, -3) [nodestyle] (uS2) {$uS(t_0)$};
  \node at (-1, -3) [nodestyle] (dS2) {$dS(t_0)$};
  \node at (-3, -3) [nodestyle] (d3S) {$d^3S(t_0)$};

  \node at (-4.5,  0) [] (t0) {$S(t_0) =$};
  \node at (-4.5, -1) [] (t0) {$S(t_1) =$};
  \node at (-4.5, -2) [] (t0) {$S(t_2) =$};
  \node at (-4.5, -3) [] (t0) {$S(t_3) =$};

  \path[-latex]
     (S1) edge (uS)
     (S1) edge (dS)

     (uS) edge (S2)
     (dS) edge (S2)
     (uS) edge (u2S)
     (dS) edge (d2S)

     (u2S) edge (u3S)
     (u2S) edge (uS2)
     (S2)  edge (uS2)
     (S2)  edge (dS2)
     (d2S) edge (dS2)
     (d2S) edge (d3S);
\end{tikzpicture}

\vspace{2mm}

\caption{Binomial lattice for three periods ($u\cdot d = 1$)}
\label{fig:binomial-tree}
\end{figure}
  
\end{frame}


\begin{frame}
  \frametitle{Observation}

  \begin{itemize}
  \item There is no way to synchronize between threads in a single
    block.
  \item We only have the choice of no synchronization or
    synchronization across all blocks
  \item We cannot force Accelerate or Nikola to use just a single
    block.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Option pricing: Least-Squares Monte Carlo}
   \begin{figure}
       \centering
       \includegraphics[width=\textwidth]{graphics/lsmplot.pdf}
       \vspace{-5mm}
       \caption{}
   \label{fig:2dsobolseq}
 \end{figure}  
\end{frame}

\begin{frame}
  \frametitle{Sobol-sequence generation}
   \vspace{-5mm}
   \begin{minipage}[t]{0.48\linewidth}
     \begin{figure}
       \centering
       \includegraphics[width=\textwidth]{graphics/2D-sobol-sequence.pdf}
       \vspace{-5mm}
       \caption{2D Sobol-sequence}
   \label{fig:2dsobolseq}
 \end{figure}

  \end{minipage}
  \begin{minipage}[t]{0.48\linewidth}
    \begin{figure}
      \centering
      \includegraphics[width=\textwidth]{graphics/2D-mersenne-sequence.pdf}
      \vspace{-5mm}
      \caption{2D Mersenne Twister Sequence}
  \label{fig:2dmersenne}
\end{figure}

  \end{minipage}
  \pause
  \vspace{6mm}
  \begin{equation*}
    \mathsf{SobolInductive}~v~i~=~\textbf{reduce}~(\oplus)~0~(\textbf{zipWith}~(\cdot)~v~(\textsf{ToBitVector}~i))
  \end{equation*}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Sobol-sequence generation}

What we want:

  \quad$\mathsf{SobolInductive}~v~i~=~\textbf{reduce}~(\oplus)~0~(\textbf{zipWith}~(\cdot)~v~(\textsf{ToBitVector}~i))$
  ~\vspace{2mm}\pause
  
  \quad$\mathsf{SobolSequence1D}~m~v~=~\textbf{parmap}~(\textsf{SobolInductive}~v)~[1..m]$
  ~\vspace{2mm}\pause

  \quad$\mathsf{SobolSequenceND}~m~vs~=~\textbf{parmap}~(\textsf{SobolSequence-1D}~m)~vs$

~\vspace{5mm}\pause

What we have to do:
\begin{itemize}
\item Make $m$ replicas of $vs$ to form a cube
\item Create a cube of equal size containing all the bit vectors
\item Then use \textbf{zipWith} and \textbf{reduce} as before
\end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Observations}

  \begin{itemize}
  \item<1-> Rely on fusion to avoid memory overhead
  \item<2-> Incompositional
  \item<3-> Limited possibilities for abstractions
  \item<4-> Library writing seems infeasible
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Sobol-sequences take \#2}
  \begin{algorithmic}
    \Function{SobolSkipping}{$v$, $n$, $p$, $b$}
%    \State $p \gets$ number of processor cores (e.g. CUDA cores)
%    \State $r \gets \lfloor n/m \rfloor$
    \ParFor{$i \gets 1$ \textbf{to} $2^{p+b}$}
    \State $x_i \gets$ \textsc{SobolInductive} $v$ ~(\textsc{GrayCode} $i$)
    \While{$i < n$}
    \State $q \gets lsb(i \blor (2^{p+b} - 1))$
    \State $x_{i+2^{p+b}} \gets x_i \oplus v_{p+b}~\oplus v_q$
    \State $i <- i+2^{p+b}$
    \EndWhile
    \EndParFor
    \EndFunction
  \end{algorithmic}

  \vspace{1cm}
  Source: Thomas Bradley, Mike Giles et al. 'Parallelization Techniques for Random Number Generators'

% {\footnotesize
% \begin{verbatim}
% unfold :: (Shape sh, Elem a)
%        => Int -> (Int -> a -> a)
%        -> Array sh a -> Array (sh :. Int) a
% \end{verbatim} }

% {\footnotesize
% \begin{verbatim}
% unfold :: (IsElem a, IsElem (Exp t Ix), Shape sh, Source r a)
%        => Exp t Ix
%        -> (Exp t Ix -> a -> a)
%        -> Array r sh a
%        -> Array PSH (sh :. Exp t Ix) a
% \end{verbatim} }
\end{frame}


\begin{frame}[fragile]
  \frametitle{Sobol-sequences take \#2}

\textbf{unfold} :: (Shape sh, Elem a) $\Rightarrow$
                
\hspace{1.4cm}Int $\rightarrow$ (Int $\rightarrow$ a $\rightarrow$ a) $\rightarrow$ Array sh a $\rightarrow$ Array (sh :. Int) a

\vspace{7mm}
  \begin{algorithmic}
    \Function{SobolSkipping-Unfold}{$v$, $n$, $p$, $b$}
    \State $xs \gets$ \textbf{parmap} (\textsc{SobolInductive} $v$ $\circ$ \textsc{GrayCode}) $[1..2^{p}]$
    \State $ys \gets$ \textbf{unfold} $n$ ($\lambda i. \lambda x_i$. \textsc{SkipAhead}($v$, $p$, $b$, $i$, $x_i$)) $xs$
    \State \Return $ys$
    \EndFunction
  \end{algorithmic}


% {\footnotesize
% \begin{verbatim}
% unfold :: (IsElem a, IsElem (Exp t Ix), Shape sh, Source r a)
%        => Exp t Ix
%        -> (Exp t Ix -> a -> a)
%        -> Array r sh a
%        -> Array PSH (sh :. Exp t Ix) a
% \end{verbatim} }
\end{frame}


% \begin{frame}
%   \frametitle{How it breaks down}
%   \begin{itemize}
%   \item Composability is lost.
%   \item Will it still break down if we wrap it in another map?
%   \end{itemize}
% \end{frame}

\begin{frame}
  \frametitle{Nested array operations}

  The same operations can execute in several ways:

  \begin{itemize}
  \item \textbf{mapP} - independent parallel threads
  \item \textbf{mapS} - sequential loop on the device
  \item \textbf{mapSeqPar} - execute the kernels in strict sequence
  \end{itemize}
  ~\vspace{2mm}\pause

  We can now write:
  ~\vspace{2mm}

  \hspace{1mm}$\mathsf{SobolInductive}~v~i~=~\textbf{reduceS}~(\oplus)~0~(\textbf{zipWith}~(\cdot)~v~(\textsf{ToBitVector}~i))$
  ~\vspace{2mm}\pause
  
  \hspace{1mm}$\mathsf{SobolSequence1D}~m~v~=~\textbf{mapP}~(\textsf{SobolInductive}~v)~[1..m]$
  ~\vspace{2mm}\pause

  \hspace{1mm}$\mathsf{SobolSequenceND}~m~vs~=~\textbf{mapSeqPar}~(\textsf{SobolSequence-1D}~m)~vs$

\end{frame}



\begin{frame}
  \frametitle{Block level synchronization}

  It is also possible to stay in a single block:

  \begin{itemize}
  \item mapB - independent parallel threads using only in a single block
  \item mapSeqParB - sequential map with device synchronization between each map.
  \end{itemize}


  BinomialPortfolioPricer = \textbf{map} (\textbf{foldl} (\textbf{map} ...) ...)

  Could be parallized by: \textbf{mapP} (\textbf{foldlSeqParB} (\textbf{mapB} ...)
\end{frame}

\begin{frame}
  \frametitle{Ordering}
  \begin{itemize}
  \item \textbf{S} can occur within \textbf{P} or \textbf{B} operations
  \item \textbf{B} can occur within \textbf{SeqPar}, \textbf{P} or \textbf{SeqParB} operations
  \item \textbf{SeqParB} can occur within \textbf{SeqPar}, \textbf{P} or \textbf{SeqParB} operations
  \item \textbf{P} can occur within \textbf{SeqPar} operations
  \item \textbf{SeqPar} can occur within \textbf{SeqPar} 
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Sequential}

  \begin{itemize}
  \item This selection should be automated.
  \item We let parallelism flow inwards
  \item Stops when a special \textbf{sequential}-cursor is met
  \item We are far from finished implementing it in Nikola
  \item How should a library designer behave
  \end{itemize}

  Example:  <some code>

  Is assigned the following execution semantics: <some code>

\end{frame}

\begin{frame}
  \frametitle{Sequential}
  \begin{center}
    {\Large Demo time! }
  \end{center}
\end{frame}


\begin{frame}
  \frametitle{Sequential and fusion}
  Fusion should happen before execution semantics
\end{frame}

\begin{frame}
  \frametitle{Future work}
\end{frame}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-engine: luatex
%%% End: