% Make space in the table of contents so the conclusion and
% bibliography is separate from the Language Extension-part
\addtocontents{toc}{\protect\vspace{10pt}}

\chapter{Conclusion}
\label{chap:Conclusion}
\section{Future Work}


\subsection{Nested data-parallelism on NVIDIA Kepler GPUs}
On newer GPUs supporting CUDA 5.0, such as the one we have had access
to, allows for 20 levels of nested calls, such that a kernel can spawn
other parallel kernels directly on the GPU, without returning to the
CPU. NVIDIA uses the term \emph{dynamic parallelism}\footnote{A short
  example is provided in
  \url{http://developer.download.nvidia.com/assets/cuda/docs/TechBrief_Dynamic_Parallelism_in_CUDA_v2.pdf}}

We only discovered this late in the project, and we have thus not
contemplated much on the idea of employing them for our
\lstinline{mapNest}-function. It should definitely be consider to use
new hardware capabilities for the problem, and it thus a thing that
would be worth looking closer at in the future.

\subsection{Prototype implementation of \texttt{sequential}}
Our idea of 'sequential' should have been introduced in previous
sections, but we should suggest implementing it more fully than we
have had time to and investigate which complications will arise, which
further extensions that are possible. All in all, we believe there is
a great potential in a \texttt{sequential}-construct, although we can
not do much more than speculate on the implementability and
practicality.

For further ideas for future work on \lstinline{sequential}, see
Chapter \ref{chap:directing-parallelism}.

\subsection{Broader scope of survey}
Many languages was left out in our survey, and only few parallization
patterns have been tested. It would thus be worth extending our survey
to cover other languages such as Theano, Feldspar, Obsidian, Bohrium
and Copperhead.

When it comes to algorithms implemented, we would like to implement
portfolio option pricers for both the binomial model and the LSM
algorithm, as they might giver better idea about the performance of
the languages for embarassingly parallel tasks.

On a final note about the future of our survey, we have during the
project found that this community of data-parallel languages, really
need a way of comparing their work, to make it more competitive. We
suggest that the community takes inspiration from the Computer
Languages Benchmark
Game\footnote{\url{http://benchmarksgame.alioth.debian.org/}}, and
creates a similar comparison between data-parallel languages where
results are updated regularly. There could be both a CPU and a GPU
category.

For further ideas for future work on \lstinline{sequential}, see
Chapter \ref{chap:directing-parallelism}.


% \item Cite SPL and the PJ/LexiFi paper and suggest using Longstaff and
%   Schwartz for pricing their contracts.
% \item Loop constructors for Nikola's \lstinline{P} monad (e.g. fold, see binomial example).
% \end{itemize}

\section{Conclusion}
\label{sec:conclusion}

In this master's thesis we have explored the state of contemporary
data-parallel languages, with a focus on functional programming
languages. We have compared the embedded languages Nikola and
Accelerate with the Haskell libraries \lstinline{Data.Vector} and
Repa, and with the programming languages R and CUDA.  This we did by
selecting and describing a set of algorithms from the financial
domain, and comparing the merits of the implementation in each of
these languages.

In our comparison we uncovered great differences among the languages in both
expressive power and performance. Some of these findings confirm our
expectations from inspection of the superficial circumstances regarding each
language, such as the conjecture that Haskell programs in general have an
advantage to R in being compiled rather than interpreted, though R can make up
for this with rich, optimised foreign function bindings, as witnessed by Figure
\ref{fig:lsm-cpu-speedup}.

More interestingly, we have described some of the protruding differences
between Accelerate and Nikola, both in terms of expressive power and
performance.

Accelerate adopts the view that only programs with a guaranteed effective
implementation should be expressible. This view is manifest in the decision
that Accelerate only exposes flat data parallel constructs, and delegates to
the compilation process the task of fusing the different components of an
Accelerate program into a coherent whole.  We found however that this
limitation of expressivity was not only hindering us from implementing our
cases at all, but also resulted in inferior performance relative to Nikola.
While we do not say that it will be impossible to improve the quality of the
optimisations of Accelerate to make it competitive, we do consider it
detrimental to the current state of the language, being both difficult to use
and slow as well.

Nikola we found to have taken an opposite approach, namely to take an offset in
the capabilities of hardware, and thus exposing language constructs that more
closely correspond to those capabilities.  While this results in a language
that tris to give less static guarantees about performance and safety, we also
found the result to be a more extensible language, with a much smaller
conceptual gap between the language and the hardware. While this arguably
reduces the theoretical optimization options, our concrete finding for now was
that Nikola programs had more expressiveness available to them, and resulted in
better performance than their corresponding Accelerate implementations.

We thus reasoned that choosing Nikola would yield a path with better chances
for incremental improvements in both performance and expressivity, perhaps
eventually towards the theoretical ideal of static guarantees employed by
Accelerate.

Having selected Nikola for further study, we first sat out to improve the
expressivity of the language, by implementing an operation for iterative array
construction, and by bypassing the restriction of nested expression by
permitting nested maps. Because we do not give up the restriction of only
allowing regular arrays, some caveats apply to the use of nested maps, as we
have no way to ascertain statically that the mapped function does not yield
arrays of different shape depending on the input.

Unfortunately, due to the selecting of Nikola happening relatively late in the
progression of the project, we have not been able to get our extensions working
properly. We have however presented speculations of a possible solution to the
compilation problem of nested vector operations through the
\lstinline{sequential} construct, inspired by how Repa allows the programmer to
dictate the parallel or sequential execution mode by means of the
\lstinline{computeS} and \lstinline{computeP} functions.

We reccommend the notion of dividing execution mode by the means of markers
such as \lstinline{sequential} as a relevant topic for future research, due to
its apparent simplicity and versatility.

On a meta-project level, we found out that carrying out a research project with
a significant amount of unspecified direction can be very challenging,
especially in combination with an eventual project deadline, and the
complications of working together.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
