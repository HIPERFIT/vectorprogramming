In this chapter we present our takes on adding support for expressing
iteratively defined arrays.  Unfortunately we have not been able to get any of
these extensions completely ready for use and possible inclusion into Nikola.
We will however give an analysis of what is lacking for a more complete
implementation.

All our efforts on iterative array construction draw on Nikolas implementation
of 'push' arrays. As mentioned earlier, delayed arrays and push arrays are each
others opposites. Delayed arrays are \texttt{Source} arrays, and their
manifestation is at the mercy of the consumer of the array -- Therefore it is
required that the elements of a delayed array are completely independent from
each other.  Push arrays on the other hand are defined as a stream of
index-value pairs, and thus need not obey the same restriction on element
dependence.

Push arrays in Nikola are defined by means of the for-loop constructor \texttt{ForE}
of \texttt{S.Exp}. This loop constructor however, is very low-level in the
sense that it includes as arguments a list of variables to be looped over and a
list of loop bounds corresponding to each of the variables.

The \texttt{Shape} typeclass defines an accessible interface for constructing
for-loops that visit each index of given shape to loop over.  The operation
\texttt{seqfor :: Shape sh => sh -> P sh} that we use for constructing our
loops is defined using the \texttt{shift} action, and thus needs to be paired
with an enclosing \texttt{reset}.  Due to the way that \texttt{shift} operates,
what happens is that upon issuing \texttt{seqfor} in the \texttt{P} monad, the
entire surrounding action up to the nearest enclosing reset is placed inside
the body of the for-loop defined by \texttt{seqfor}.

However to our regret, using this approach for defining the operators discussed
below proved unfruitful, as the part of the C code generation that pertains to
for loops in Nikola does not handle cross-iteration data dependencies properly,
assuming that variables overwritten inside the body of the loop constitute new,
fresh variables. Due to our time constraints we were not able to address this,
and have to leave our operations be for now. If however we disregard this
problem, we are not aware of any more obstacles for implementing our extensions
properly.

\section{unfolding and nested maps}

Since it is not possible to use recursion in Nikola to incrementally construct
arrays, there must instead be provided some other primitive iterative operator.
We have turned our attention towards the common \texttt{unfoldr} list operator
for inspiration.

In Haskell, \texttt{unfoldr} has the type \texttt{(b -> Maybe (a,b)) -> b ->
[a]}.  \texttt{unfoldr f a} recursively populates the element of a list with
\texttt{f}, as long as it evaluates to \texttt{Just (a,b)}.

In Nikola the length of an array is the only intrinsic property shared across
all array representations. Therefore we must know the length of the result array a
priori to evaluating a Nikola \texttt{unfoldr}.

For a prototype that only uses the last generated element as state, we settle
for the type signature:
\begin{verbatim}
unfold ::
  Shape sh =>
  IsElem a =>
  Typeable a =>
    sh ->
    (sh -> a -> a) ->
    a ->
    Array PSH sh a
\end{verbatim}

In order to be useful however, \texttt{unfoldr} by itself is not enough.
Iteratively producing entire rows or columns of a matrix as required in
algorithm \ref{alg:lsm} would require the function to be unfolded to produce
arrays, which is impermissable.

To remedy this, we set out to explore nested maps. Again, lacking nested arrays
we must use array shapes to express the structure of our computation.  Like in
the case of \texttt{unfoldr} we thus must express the resulting shape beforehand.

The type we eventually arrived at for our maps capable of nesting is depicted
here:
\begin{verbatim}
mapNest ::
  Shape sh =>
  Shape sh' =>
  IsElem a =>
  IsElem (Exp t Ix) =>
  IsElem b =>
  Source r a =>
      sh' -> (Exp t Ix -> Array D sh a -> Array PSH sh' b)
          -> Array r  (sh :. Exp t Ix) a
          -> Array PSH (sh' :. Exp t Ix) b
\end{verbatim}

While we require the shape \texttt{sh'} to be specified, there is no guarantee
in the application \texttt{mapNest f xs} that \texttt{f x} will not produce an
array exactly the size denoted by \texttt{sh'}. If the resulting array is
smaller than denoted by \texttt{sh'}, an eventual manifestation of the map to
memory will leave some cells uninitialized. Similarly, if the resulting array
is not bounded by \texttt{sh'}, manifesting it will result in writing out of
bounds.

For now we have chosen to accept the existence of these fallacies, partly
because we are concerned with implementing a prototype, and partly because we
don't see any acceptable resoultion of the problem beyond placing the actual
array extent rather than just the shape into the type of the array.

Another issue with this definition is the \texttt{Source r a} restriction on
\texttt{xs}. If the mapped function does not need to index into the array, it
is an unnecessary restriction to impose.  Similarly, if the mapped function
performs only elementwise operations, preserving the porperty of being
indexable would be valuable to retain for possible further processing of the
result array.

Risking to further complicate the types, the situation is somewhat remediable
by defining \texttt{mapNest} as a function in a typeclass parametrised over the
involved array representations, as is already the case for typeclass
\texttt{Map} in module \texttt{Data.Array.Nikola.Operators.Mapping}.

\subsection{Intrinsically mapped unfold}

Our first attempt at defining an unfolding operation was inspired by the
collective operators of Accelerate.

\begin{verbatim}
unfold ::
  IsElem a =>
  IsElem (Exp t Ix) =>
  Shape sh =>
  Source r a =>
    Exp t Ix -> (Exp t Ix -> a -> a)
    -> Array r sh a -> Array PSH (sh :. Exp t Ix) a
\end{verbatim}

By avoiding the need for a nested map, it is guaranteed that the resulting
unfolded arrays all have the same size. However, upon realizing that we would
be able to define a nested mapping operation, we felt that that was a more
compositional approach, being able to map any function on arrays.

An inviting property of this version however is that the its type is a bit
simpler, as one does not need to concern oneself with shape specifications
beyond the desired length of the unfolded arrays.

