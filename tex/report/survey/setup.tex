\chapter{Survey scope and methodology}

%\section{Motivation}
% Why do we want to do a language comparison?
%
% * Orient ourselves
%
% * No such survey exists with a scope similar our scope.
%
% * Look for common problems, how this problem should be attacked, also
%   in future research at the HIPERFIT research center

In this and the following chapters we present a small-scale survey of
a few current vector languages. The survey was originally conducted to
orient ourselves in the current landscape of data-parallel functional
languages and their implementation, but the results might be of
interest for others. We do not know of other comparisons with a
similar scope.

We will also identify some key issues used in some of the current
languages, which will be valuable knowledge for future research in the
area.

In the rest of this chapter we define the scope of our survey and go
through the methodology we have followed.

\section{Scope}
\subsection{Subject languages}
% Alternative title: "Scope: Language"
% Which languages are we comparing? Why this selection?
%
% * R because of use for prototyping in finance
%
% * CUDA because of of its use for high-performance computing in finance
%
% * Repa and Vector for popular functional approaches to data-parallel languages.
%
% * Nikola and Accelerate because of being new approaches targeting GPU
%
% * We would initially also include both Feldspar, Obsidian, Data
%   Parallel Haskell, Copperhead and GPU-NESL, lack of time (and project stability) made it impossible.
%
% * We have later also found Bohrium, Theano and CnC-CUDA (perhaps others?)
%   interesting to include, if we were to extend the survey in the future.
\todo{insert references to languages mentioned}
As this is a half-year project, we had to limit our survey
considerably in size, and thus only included a few programming
languages. We decided to evaluate and compare R, CUDA, Accelerate
\cite{chakravarty2011accelerating}, Repa \cite{keller2010regular},
Nikola \cite{mainland2010nikola} and the \texttt{Data.Vector}
library\footnote{\url{http://hackage.haskell.org/package/vector}}. 

Nikola and Accelerate was included in the survey as they are
functional approaches to GPU computation. We had initially also wished
to include Obsidian\cite{svensson2011obsidian},
Copperhead\cite{Catanzaro2011} and GPU-NESL\cite{bergstrom2012nested}
in this category, but time constraints and installation problems made
us leave them out.

The remaining languages included in the survey are not meant as being
subjects for the study, but to serve as reference models for the
comparison.

We have included the R programming language and NVIDIA's CUDA platform
because of their use in the financial industry and research
communities. Financial engineers and mathematicians use R for quick
prototyping and expressing algorithms succinctly and CUDA when
high-performance computing is required. Repa and \texttt{Data.Vector}
are two Haskell libraries, that provides array operations for
CPU-execution. They are included, because of their popularity as
functional approaches to data-parallel programming languages. R, Repa
and \texttt{Data.Vector} are thus mostly included to evaluate how easy
the Nikola and Accelerate languages are to \texttt{use}. Whereas CUDA
is included as a measuring stick and goal for their performance in
execution speed.

Since we initially started, we have discovered several other languages
which would have been interesting to look closer at. These include
Bohrium\cite{homepage:bohrium}, Theano\cite{bergstra2010theano},
CnC-CUDA\cite{grossman2011cnc} and R+GPU\cite{homepage:rgpu} (library
of common R functions running on CUDA).

\subsection{Experiments} %PLC: 'perspective' is a bit too vague in my oppinion.
% Alternative title: "Scope: Experiments"
% What do we want to measure?
%
% * Can our sample financial algorithms be written in the tested languages?
%
% * Are the necessary implementation techniques idiomatic, such that
%   others would be able to learn the language once and apply it to other
%   similar problems? And such that the employed algorithm stays clear
%   (``programs must be written for people to read, and only incidentally
%      for machines to execute'', SICP)

% * Do we obtain good performance by writing programs in the idiomatic
%   style of the language?

% * (Something to motivate spending time on the project health section
%   ??? - perhaps wait until the project health section is rewritten
%   with this)

% * How do the languages practically compare in performance? Are
%   Accelerate and Nikola close to optimized CUDA implementations?

There are several aspects of the languages that we want to examine,
falling into the three categories:

\begin{description}
\item[Expressiveness] To which extent are the languages easy to work
  with, express ones thought, mathematical expressions and established
  algorithms. 

  Specifically, we want to test whether the selected languages allows
  us to write the financial algorithms presented in Section
  \ref{chap:cases}, and that the underlying algorithm remains readable
  when implemented. Quoting a famous line from \emph{Structure and
    interpretation of computer programs} \cite{abelson1996structure}:

  \begin{quote}
    ``Programs must be written for people to read, and only
    incidentally for machines to execute''
  \end{quote}

  We thus want to check that the techniques necessary for implementing
  our sample programs does not insert unnecessary clutter.
  
\item[Project health] Here we want to take the side of the library
  user that has to select a stable library for some program, and we
  thus want to determine which projects are the most stable.

\item[Performance] In the last section we want to establish how the
  languages in practice compare in raw execution performance.
\end{description}

% \section{Surveying}
% meta-survey of how others perform programming language survey's

\section{Methodology}
\subsection{Experimentation}
% How do we want to perform the above experiments?

% * Outset was to implement both Binomial pricing and Longstaff \&
% Schwartz.

% * We knew Black-Scholes was possible in both Nikola and Accelerate (and
% thus also all other), as documented in their papers. It is thus a less
% interesting example for the Devil's advocate.

% * As Longstaff and Schwartz did not go through in either Accelerate
% and LSM we changed our scope, and put a larger focus on Sobol than the
% actual LSM algorithm.

To perform the above mentioned experiments we set out to implement
both the binomial pricing algorithm and the Longstaff and Schwartz
algorithm. 

We also considered the Black-Scholes option pricer a possibility, but
we knew that Black-Scholes was possible to implement in both Nikola
and Accelerate (and thus the remaining languages in our survey), as
they were documented in their respective research papers
\cite{mainland2010nikola, chakravarty2011accelerating}. It was thus a
less interesting example for the Devil's advocate, and as we had
enough work in implementing the binomial pricer and LSM, we ended up
leaving it out.

As we discovered that Longstaff and Schwartz was hard (perhaps
impossible) to implement in Accelerate and Nikola, we changed our
scope and put a larger focus on the Sobol algorithm than the actual
LSM algorithm.

It is from these implementations that we have documented our findings
of expressivity and performance, which will be presented in Chapter
\ref{chap:expressiveness} and \ref{chap:performance}. 

When it comes to project health, we have investigated by tracking
information about number of contributors, number of reverse
dependencies and so on, from information available on Hackage and
their commit logs. These findings are presented in Chapter
\ref{chap:project-health}.

\subsection{Result evaluation}
% How do we want to evaluate the experiments?



% In this and the following chapters we present a small-scale survey of
% a few current vector languages. The survey was originally conducted to
% orient ourselves in the current landscape of parallel functional
% languages and their implementation, but the results might be of
% interest for others. We do not know of other comparisons with a
% similar scope.

% \section{Languages}
% We have decided to evaluate and compare the languages Accelerate
% \cite{chakravarty2011accelerating}, Repa \cite{keller2010regular},
% Nikola \cite{mainland2010nikola} and the \texttt{Data.Vector}
% package\footnote{\url{http://hackage.haskell.org/package/vector}}. We
% compare these four libraries to the R programming language and
% NVIDIA's CUDA platform, which are some of the languages currently used
% by financial engineers
% %\todo{cite - that both are used in finance}.
% The R language is used for expressing financial algorithms
% succinctly, while CUDA is used for performance reasons, which is why
% we have chosen to include both of these. Because of time constraints,
% we have had to limit ourselves more than we had originally
% intended. This means we have had to leave out languages such as
% Feldspar\cite{axelsson2010feldspar},
% Obsidian\cite{svensson2011obsidian}, Data Parallel Haskell \cite{keller2010regular},
% Copperhead\cite{Catanzaro2011} and NESL\cite{nesl} from the survey,
% although they might have provided further insights. Also, as noted
% previously, we have not been able to implement the complete Longstaff
% and Schwartz algorithm in neither Nikola or Accelerate
% \todo{make sure this is indeed written down somewhere in the previous chapter}.

% %\todo{Why only Haskell? Are there any languages we have left out
% %  entirely? What about Theano, ArBB, Qilin, Erlang, SaC, CnC-CUDA? Why
% %  aren't they here?}

% \section{Programming language surveys}
% To make a fair comparison, we have to be objective in our evaluation
% of the languages. Obtaining objectivity in such a comparison is not
% an easy task, as it is hard to quantitatively measure aspects such as
% the quality of language documentation (longer is not always better,
% and it might be outdated). Also, as mentioned by Lutz Prechelt in his
% 2001 paper ``Empirical Comparison of Seven Programming Languages'':

% \begin{quote}
%   ``Any programming language comparison based on actual sample programs
%   is valid only to the degree to which the capabilities of the
%   respective programmers using these languages are similar.''
% \end{quote}

% We would thus have to either acquire the same level of experience in all the
% languages ourselves or find experts in each of the languages to do the
% implementation. We have not had the resources to conduct a survey
% following the standards set in the paper by Lutz Prechelt. For each
% language under comparison he acquired 10-20 implementations of the
% same algorithm from different programmers (mostly graduate
% students). We could have set up a similar experiment by presenting a
% programming challenge to the ``Haskell-Cafe''-mailing list and/or the
% Haskell section on the Reddit website, and surely we could perhaps get
% a decent benchmark in terms speed and memory usage for different
% implementations by different developers, but we would not get answers
% to qualitative questions about the development process. Another aspect
% is that these languages are all in their early stages, and most people
% we would find on those channels might be amateurs. We do not find
% amateur work a good basis for an objective comparison.

% %\todo{could still be an interesting experiment to make in the future.}
% %\todo{look through the above argument again}

% \section{Comparison Metrics}
% From the survey we want to uncover three main questions about each
% language, and it is from answers to these questions that we will make
% a comparison. The three questions revolve around the health of
% the project, the expressiveness and ease of use of the language, and the
% performance of the language. The following three sections will pose
% these questions and describe how we have decided to test them.

% \subsection{Project Health}

% How good is the project health? That is, we want to determine how likely is it
% that development on the language will continue and that it will keep getting
% funding and interest from developers.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% End:
