% \subsection{Ease of use and expressiveness}

% How easy is the language to use? And how expressive is it? Our
% aim is to find a language that might be suitable for a financial
% engineer and we thus want a suitably high-level language. It should
% be near the complexity level of R. We still want the language to
% expressive enough to cover the domain of financial algorithms.

% Subquestions include
% \begin{itemize}
% \item Which programs can we write, and which can't we write?
%   \begin{itemize}
%   \item Can we write nested loops?
%   \item Does it include all of: scans, folds, zip/map, stencils?
%   \item Do we have access to general recursion?
%   \end{itemize}
% \item How good are the error messages?
% \item How high-level is it on the scale from ``R'' to ``CUDA''?
% \end{itemize}

\chapter{Language Discussions}
% ``How tight is the correspondence to the Rolfs R-code?''

\todo{Compare the "coding experience" of R and CUDA. what is the level of
abstraction? Tools available? How advanced tools are required to debug? }

\section{CUDA/C}

Since CUDA/C is close to a one-to-one mapping of hardware abilities to language
primitives, it is possible though not necessarily easy to implement anything
that the hardware is capable of running.

Every single resource must be explicitly managed -- there is not even a
function call stack. While this enables the coding of very fast algorithms,
programs are also more tightly coupled with the parameters of the hardware, and
to assumptions about input size. So even though a CUDA programmer has access to
highly optimised linear algebra libraries such as CUBLAS \cite{CUBLAS2013},
optimisations such as loop fusion must be coded by hand, ruling out using such
libraries. This optimisation often has profound effects on performance
\cite{mainlandhaskell}.

When implementing the binomial option pricer in CUDA, we relied on example code
from the CUDA SDK provided by Nvidia \cite{CUDAbinomial}, as we assumed this to
be a good sample of real-world CUDA code. This example code was in fact
specialised to price a portfolio of options rather than a single option, and as
seen in the performance evaluation it scales less well than Nikola.
\todo{check that this is actually true once the performance section has been written.}

Adapting the CUDA pricer to use just a single option proved to be a substantial
and error prone effort for us.

\section{R}

\section{Repa}
\section{Accelerate}

\todo{mention accelerate backend/frontend partitioning, because it is a relevant contrast with Nikola.}

Accelerate provides a variety of array operations: Both scans, segmented scans,
folds, permutations, maps and zips. Arrays may be multidimensional, denoted by
a type variable in the same style as Repa.

Reductions (folds) are defined on arrays of arbitrary rank by performing the
reduction on the innermost dimension, yielding an array with rank one less.
Maps are all elementwise regardless of the shape of the input array, and scans
are only defined on one-dimensional arrays.

Accelerate is characterised by a clean division between the frontend and the
various backends that exist. The Accelerate language thus is completely backend
agnostic, and backends simply export a function such as \texttt{run :: Acc a ->
a}.

Accelerate employs a meticulus partitioning of functions on arrays and functions
on scalar values. Array functions are all embedded in the \texttt{Acc a} type,
while scalars are embedded in the \texttt{Exp a} type. So, everything that is
capable of reducing an array or producing an array is carefully placed inside
\texttt{Acc}, and the functions usable for elementwise computation must
reside in \texttt{Exp}. Thus, the lack of nested parallelism is directly
encoded in the type system.

While this restriction probably makes it easy to ensure efficient execution of
the individual contructs, it impairs the composability of the language
constructs significantly, as the programmer needs to manually transform
algorithms with a naturally nested defintion into something that will fit into
the view of Accelerate.

Consider this small example, derived from a problem we actually encountered
while exploring the sobol sequence generation case:

Suppose we have a function \texttt{f} performing a simple vector operation,
such as multiplying a scalar.

\begin{verbatim}
f :: Vector a -> b -> Vector c
f as b = map (b *) as
\end{verbatim}

Now, if we want to do scalar multiplication with a vector of scalars, in
\texttt{Data.Vector} haskell, this is what we could reasonably write:

\begin{verbatim}
g :: Vector a -> Vector b -> Vector (Vector c)
g as bs = map (f as) bs
\end{verbatim}

If we set out to code this program in Accelerate we would have a similar
\texttt{f}:

\begin{verbatim}
f :: Acc (Vector a) -> Exp b -> Acc (Vector c)
f as b = map (b *) as
\end{verbatim}

But since we don't have nested arrays in Accelerate, we need to model the
\texttt{Vector (Vector c)} type  as \texttt{Acc (Array DIM2 c)}. Thus we end up
wanting the function \texttt{g} below, defined using \texttt{f}.

\begin{verbatim}
g :: Acc (Vector a) -> Acc (Vector b) -> Acc (Array DIM2 c)
\end{verbatim}

But there seems to be no way to construct a high-dimensional array from array
functions of lower dimension. So we need to rewrite \texttt{f} itself:

\begin{verbatim}
g as bs = generate
  (index2 $ (size as) (size bs))
  (\ix ->
  let (Z :. ia :. ib) = unlift ix
  in bs ! (Z :. ib) * as ! (Z :. ia))
\end{verbatim}

Furthermore, this is only possible because \texttt{f} is itself defined by an
elementwise operation. Had \texttt{f} been defined by a reduction such as
\texttt{fold}, the transformation would have been even more elaborate and
require replication of both vector \texttt{as} and \texttt{bs} and zipping to
properly distribute \texttt{b} into the folding operation.

\todo{It would be really nice to have a proper explanation of this, preferably
with an illustration of the replication. But that is definitely beyond our
current schedule}
\todo{Add Accelerate Sobol-example as appendix, reference it here - hand drawing?!}

This sharp division between scalar and array operations is easily the biggest
hindrance to the expressiveness of Accelerate, and therefore very relevant to
our interest in language research. However, as this is a pervasive part of the
architecture of Accelerate, removing the distinction of \texttt{Acc} and
\texttt{Exp} would result in an entirely different language, and every single
backend would have to be rewritten.

\todo{The above paragraph sounds a bit corny..}

The embedding of Accelerate leaves some things to be desired. It is for
instance not easily possible to pattern match on tuples and shapes, as these
need to be properly lifted and unlifted to be used (see above in function \texttt{g}).

Also, lifting using \texttt{lift :: Lift c e => e -> c (Plain e)} uses the
\texttt{Plain} associated type, the definition of which is not shown in the
auto-generated documentation of instances. Although the documentation
generation system is arguably to blame for this, it does none the less make it
more difficult to easily use value lifting confidently.

There is no way to define recursive functions in Accelerate. Trying to do so
will result in compilation not terminating.

\section{Nikola}

Nikola does not provide the variety array operations that Accelerate does: Only
a few mapping operations are provided, and an iteration construct.  Nikola has
in common with Repa the differentiation of arrays by type parameter.

To exploit this, operations such as \texttt{map} and \texttt{zipWith} are
implemented using typeclasses with a single function specified.  While this
architecture allows for specialisation of operations to different array
representations, using the operations result in quite elaborate types. These
are often too compilcated for type inference to resolve and require a
programmer supplied type signature.

Compared to Accelerate, Nikola is embedded more naturally inside Haskell,
leveraging the \textt{RebindableSyntax} GHC-extension. Also, in our programming
experience we were less required to interact with the value lifting machinery
than we were in Accelerate. Value lifting in Nikola is subject to the same
documentation inadequacies as we encountered with Accelerate.

%Nikola has a lot of overall structure in common with Repa

While Nikola does not present any means for expressing nested parallelism, it
does not explicitly ban it either in the style of Accelerate's
\texttt{Acc}/\texttt{Exp} division. Thus, extending the expressive power of
Nikola in this aspect appears at first to be a less elaborate endeavour than in
Accelerate.

There is no way to define recursive functions in Nikola. Trying to do so
will result in compilation not terminating.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% End:
