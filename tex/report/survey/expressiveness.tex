\chapter{Evaluation: Expressiveness}
% ``How tight is the correspondence to the Rolfs R-code?''

\todo{Compare the "coding experience" of R and CUDA. what is the level of
abstraction? Tools available? How advanced tools are required to debug? }

\section{CUDA/C}

\todo{maybe these tow paragraphs are better suited in language introduction?}

Since CUDA/C is close to a one-to-one mapping of hardware abilities to language
primitives, it is possible though not necessarily easy to implement anything
that the hardware is capable of running.

Every single resource must be explicitly managed -- there is not even a
function call stack. While this enables the coding of very fast algorithms,
programs are also more tightly coupled with the parameters of the hardware, and
to assumptions about input size. So even though a CUDA programmer has access to
highly optimised linear algebra libraries such as CUBLAS \cite{CUBLAS2013},
optimisations such as loop fusion must be coded by hand, ruling out using such
libraries. This optimisation often has profound effects on performance
\cite{mainlandhaskell}.

When implementing the binomial option pricer in CUDA, we relied on example code
from the CUDA SDK provided by Nvidia \cite{CUDAbinomial}, as we assumed this to
be a good sample of real-world CUDA code. This example code was in fact
specialised to price a portfolio of options rather than a single option, and as
seen in the performance evaluation it scales less well than Nikola.
\todo{check that this is actually true once the performance section has been written.}

Adapting the CUDA pricer to use just a single option proved to be a substantial
and error prone effort for us.

\section{R}

\section{Repa}
\section{Accelerate}

Accelerate provides a variety of array operations: Both scans, segmented
scans, folds, permutations, maps and zips.

Reductions (folds) are defined on arrays of arbitrary rank by performing the
reduction on the innermost dimension, yielding an array with rank one less.
Maps are all elementwise regardless of the shape of the input array, and scans
are only defined on one-dimensional arrays.

Accelerate employs a meticulus partitioning of functions on arrays and functions
on scalar values. Array functions are all embedded in the \texttt{Acc a} type,
while scalars are embedded in the \texttt{Exp a} type. So, everything that is
capable of reducing an array or producing an array is carefully placed inside
\texttt{Acc}, and the functions usable for elementwise computation must
reside in \texttt{Exp}. Thus, the lack of nested parallelism is directly
encoded in the type system.

While this restriction probably makes it easy to ensure efficient execution of
the individual contructs, it impairs the composability of the language
constructs significantly, as the programmer needs to manually transform
algorithms with a naturally nested defintion into something that will fit into
the view of Accelerate.

Consider this small example, derived from a problem we actually encountered
while exploring the sobol sequence generation case:

Suppose we have a function \texttt{f} performing a simple vector operation,
such as multiplying a scalar.

\begin{verbatim}
f :: Vector a -> b -> Vector c
f as b = map ((*) b) as
\end{verbatim}

Now, if we want to do scalar multiplication with a vector of scalars, in
\texttt{Data.Vector} haskell, this is what we could reasonably write:

\begin{verbatim}
g :: Vector a -> Vector b -> Vector (Vector c)
g as bs = map (f as) bs
\end{verbatim}

If we set out to code this program in Accelerate we would have a similar
\texttt{f}:

\begin{verbatim}
f :: Acc (Vector a) -> Exp b -> Acc (Vector c)
f as b = map ((*) b) as
\end{verbatim}

But since we don't have nested arrays in Accelerate, we need to model the
\texttt{Vector (Vector c)} type  as \texttt{Acc (Array DIM2 c)}. Thus we end up
wanting the function \texttt{g} below, defined using \texttt{f}.

\begin{verbatim}
g' :: Acc (Vector a) -> Acc (Vector b) -> Acc (Array (Z :. Ix :. Ix) c)
\end{verbatim}

But there seems to be no way to construct a high-dimensional array from array
functions of lower dimension. So we need to rewrite \texttt{f} itself:

\begin{verbatim}
g' as bs = generate
  (constant $ (size as) :. (size bs))
  (\ (Z :. ia :. ib) -> bs ! (Z :. ib) * as ! (Z :. ia))
\end{verbatim}%$

Furthermore, this is only possible because \texttt{f} is itself defined by an
elementwise operation. Had \texttt{f} been defined by a reduction such as
\texttt{fold}, the transformation would have been even more elaborate and
require replication of both vector \texttt{as} and \texttt{bs} and zipping to
properly distribute \texttt{b} into the folding operation.

\todo{It would be really nice to have a proper explanation of this, preferably
with an illustration of the replication. But that is definitely beyond our
current schedule}
\todo{Add Accelerate Sobol-example as appendix, reference it here - hand drawing?!}

\section{Nikola}

For both Accelerate and Nikola it were allowed to write nested loops only to
the extent that they may be unfolded in their entirety at compile-time. For the
binomial pricer this is not a problem, as the number of loop iterations is a
simple function of the number of days simulated.  \todo{Nikola also has a
seq-loop construct?} However, for Accelerate this unfolding resulted in it
having to compile a CUDA kernel representing each loop iteration, greatly
dominating the execution time. To overcome this required some (nontrivial?)
rewriting of the code.

Because of the heavy syntactical overloading of Haskell employed by Nikola, the
code was/is? required to be divided into more small modules than is usually
required/desirable.

Repa and Vector are entirely CPU based, and are thus just normally executed
Haskell code without any explicit recompilation. As a result they suffered none
of the expressive shortcomings of Nikola and Accelerate. Thus, they closely
mirror the reference R code.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% End:
