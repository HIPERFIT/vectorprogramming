\chapter{Survey Conclusion}
In this chapter we summarise the conclusions made in the above
summary, and make suggestions for further studies. In Part
\ref{part:extensions} of this dissertation we will look closer on a
couple of the mentioned suggestions, the remaining can be seen as
future work. Additional future work, not related to the outcomes of
the survey, is presented in Chapter \ref{chap:Conclusion}.

\section{Language selection}
We have compared the libraries Accelerate, Nikola, Repa and
\texttt{Data.Vector} and our conclusion is that Nikola is the most
suitable for further extensions when the scope is GPU programming. The
Repa and \texttt{Data.Vector} architectures are not really compatible
with code-generation, as would be necessary if they had to be modified
to run on GPUs. Studying them was not entirely without results, as for
instance the \texttt{computeS} of Repa can be viewed as the originator
for the idea we will present in Chapter
\ref{chap:directing-parallelism}.

When comparing Accelerate and Nikola, we had the most pleasant
installation experience with Nikola. The restrictive type system of
Accelerate was also a factor that made us opt for Nikola. Especially
the division between the expression and vector layer of Accelerate
made us worried, as we would have to make major modifications to break
this barrier down.

Another choice is which languages would be suitable for application
development. Currently \texttt{Data.Vector} with more than 150 reverse
dependencies seems the most stable and practically useful. Repa seems
stable, though hard to get to scale, though our problems might not
have been the best fit for Repa.

The four languages that would be most likely to change in the future
is Nikola, as only skeleton of the language exist; it still lacks many
common parallel array operations such as prefix-sum, parallel
reductions. It can be seen more as a testbed, than a practical
language. Accelerate on the other hand has alot of such operations
built in as skeletons, and if we did not have had the troubles with
getting it to run on our machine, we would probably have had been more
keen at recommending it.

\section{Unfold}
\todo{Required by several of our cases, as neither Nikola nor
  Accelerate has primitives for iterative construction of arrays}
\todo{Nikola and Accelerate can only construct arrays where there are
  no dependencies between elements, through \texttt{fromFunction} and
  \texttt{generate}}

\section{Nesting}
\todo{We have shown how Accelerate and Nikola breaks down in
  cumbersome notation certain cases, where algorithms could be written
  clearly if nested layers of array operations was allowed} 

\todo{We argue that it is worth incorporating nesting in one way or
  another, and we will go into a possible way in the following
  sections}

\subsection{Directing parallelism}
\todo{Introducing nesting also requires some way to direct how
  parallelism will come about. Parallelism can be present at several
  layers, or vectorisation could be employed.}

\section{Where to synchronize}

\section{Memory reusage}

\section{Interfacing with existing libraries}

\section{Haskell infrastructure}
\label{sec:haskell_infrastructure}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% End:
