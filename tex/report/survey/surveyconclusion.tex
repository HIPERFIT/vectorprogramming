\chapter{Survey Conclusion}
In this chapter we summarise the conclusions made in the above
summary, and make suggestions for further studies. In Part
\ref{part:extensions} of this dissertation we will look closer on a
couple of the mentioned suggestions, the remaining can be seen as
future work. Additional future work, not related to the outcomes of
the survey, is presented in Chapter \ref{chap:Conclusion}.

\section{Language selection}
We have compared the libraries Accelerate, Nikola, Repa and
\texttt{Data.Vector} and our conclusion is that Nikola is the most
suitable for further extensions when the scope is GPU programming. The
Repa and \texttt{Data.Vector} architectures are not really compatible
with code-generation, as would be necessary if they had to be modified
to run on GPUs. Studying them was not entirely without results, as for
instance the \texttt{computeS} of Repa can be viewed as the originator
for the idea we will present in Chapter
\ref{chap:directing-parallelism}.

When comparing Accelerate and Nikola, we had the most pleasant
installation experience with Nikola. The restrictive type system of
Accelerate was also a factor that made us opt for Nikola. Especially
the division between the expression and vector layer of Accelerate
made us worried, as we would have to make major modifications to break
this barrier down. Another plus in the favour of Nikola, is that it
allows interaction with other CUDA libraries, e.g. CUBLAS, without
having to get the data roundtrip to the CPU and back again (see
Section \todo{ref}).

Another choice is which languages would be suitable for application
development. Currently \texttt{Data.Vector} with more than 150 reverse
dependencies seems the most stable and practically useful. Repa seems
stable, though hard to get to scale, though our problems might not
have been the best fit for Repa.

The four languages that would be most likely to change in the future
is Nikola, as only skeleton of the language exist; it still lacks many
common parallel array operations such as prefix-sum, parallel
reductions. It can be seen more as a testbed, than a practical
language. Accelerate on the other hand has alot of such operations
built in as skeletons, and if we did not have had the troubles with
getting it to run on our machine, we would probably have had been more
keen at recommending it.

\section{Unfold}
As demonstrated in Section \todo{ref}, several of our cases requires a
way of building up an array from repeated application of a
non-associative operator. Neither Accelerate nor Nikola provides
built-in functionality that can be combined to do perform such
operation. They can only construct new GPU arrays where there are no
dependencies between elements (through \texttt{generate} and
\texttt{fromFunction} respectively) or from existing CPU-arrays.

Chapter \todo{ref} will present our work on an implementation of such
an idea in Nikola.

\section{Nesting}
We have in Section \todo{ref} shown how in certain cases, both
Accelerate and Nikola breaks down in cumbersome notation, where
algorithms could be written clearly if nested layers of array
operations were allowed. We can in certain cases get out of this by
relying on fusion of a surrounding \texttt{generate} function that
indexes into the nested call. This will not work in the general case
though, as it breaks down if we for instance raise the dimensionality
of the involved arrays by one.

We argue that it is worth incorporating nesting in one way or another,
as many algorithms are more naturally expressed in a nested style.

We will go into a possible way of mapping this to GPU devices in
Chapter \todo{ref}. The method is an alternative to full vectorisation
and allows you to direct how parallelism is added to the
program. Parallelism can be incorporated at several different layers
of programs, and we thus provide a way of selecting between them.

\section{Level of synchronization}
In the implementation of the binomial option pricer we found it
necessary to synchronize on the CPU to guarentee syncronization across
all blocks. If we were to map this option pricer over a portfolio of
different options, we would instead want something different. We would
want each option to reside in their own block, and use CUDAs
\texttt{\_\_syncthreads} function to syncronize all threads in the
block.

Thus, in algorithms that requires such synchronization, an analysis
could be employed to determine when synchronization could happen in
scope of single blocks and only when necessary, synchronize all
blocks.

\section{Memory reusage}
In the binomial pricer we have seen that the performance of Nikola
degraded as it didn't reuse the same CUDA memory areas that was
already allocated, but had to reallocate space. In our case, where we
are folding over an operation that uses an array as accumulator, we
would be able to determine whether we could reuse the array from
earlier iterations. We already know the size of arrays after each
iteration, since we need to allocate space before starting the
operation, so we would be able to infer whether the accumulator would
increase in size or not.

\section{Haskell infrastructure}
\label{sec:haskell_infrastructure}
In setting up our test environment we found that \todo{}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% End:
