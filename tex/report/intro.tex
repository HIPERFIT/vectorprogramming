% Disposition for introduction:
% \begin{itemize}
% \item Where does performance and programmer efficiency come from
% \item The free lunch is over
% \item (Embarassingly parallel problems)
% \item Why the language-based approach?
% \item Parallel Functional Programming
% \item What is a "vector language"?
% \item Our strategy: implement real world example applications, study
%   limitations of current approaches, extend and modify until we get
%   better results.
% \item Report Outline
% \end{itemize}

\chapter{Introduction}
Ever since the first electronic computers were built, there has been a
wish for tackling larger and more complex problems, which in turn has
created an increasing demand for performance improvements and
increased programmer productivity. Performance improvements originate
from improvements in either hardware or the employed
algorithms. Programmer productivity, on the other hand, correlates
with the features of the used programming language and programming
environment (IDEs, debuggers, etc.). A language providing high
programmer efficiency should make it easy to implement and reason
about algorithms, make mistakes easily avoidable and when a mistake
happens, make it easy to uncover its cause. \todo{cite}

For a handful of decades, we have been able to increase performance
through hardware improvements of sequential processors and we have
thus been able to stick with more or less the same model of
computation. Recently, hardware developers have faced physical
barriers, making further performance improvements of sequential
processors impractical, and they have had to go new ways to obtain the
desired speed-up \cite{sutter2006freelunchisover}. These new architectures call
for new algorithms and models of computation, as well as new languages
and programming tools to keep the complexity of software development
at a tolerable level.

We will focus on software development for \textit{graphics processing
  units} (GPUs), which were originally intended solely for computer
graphics, but have in recent years been found useful in many other
applications, such as bioinformatics, medical image analysis,
computational finance and simulation in engineering and the sciences
\cite{hwy2011emerald, hwu2011jade, owens2007survey}. They have gained
so much popularity that they are a main ingredient in quite a few of
todays largest supercomputers \cite{Top500}.

Even though we think of graphics processors as \textit{modern
  hardware}, the software development tools in widespread use for
programming them are far from modern. CUDA
\cite{nvidia2012programming} and OpenCL \cite{munshi2011opencl}, the
two main languages for programming GPUs are low-level languages with
manual memory management, limited abstractions, and they require
tedious hand optimization, as you for instance have to streamline your
memory access to get decent performance. The low-level nature of these
languages makes it hard to do any better, as automated code analysis
is difficult with generalized loops and pointers. The NVIDIA CUDA
compiler thus cannot make the optimizations with largest impact on
performance, such as stream fusion (deforestation), that removes
intermediate data structures and thus removes the need for very costly
memory transactions.

\section{Vector programming languages}
Alternative approaches to GPU programming have been tried out, but
none of them have found as widespread use as programming directly in
CUDA or OpenCL. Such higher level languages include Theano\cite{bergstra2010theano},
Accelerate\cite{chakravarty2011accelerating},
Nikola\cite{mainland2010nikola}, Obsidian\cite{svensson2011obsidian},
Intel Array Building Blocks \cite{newburn2011intel}, Bohrium
\cite{homepage:bohrium} and Copperhead \cite{Catanzaro2011}.

We call these languages ``Vector languages'' as they share the
characteristica of lifting operations to work collectively on vectors
rather than individually on primitive values (such as integers and
floating point number). In Nikola and Accelerate this is implemented
by making it impossible to evaluate a primitive expression without
lifting it to work on vectors.

Applying the same operation to a large number of elements is the main
force of GPUs, and this thus \todo{..}

We want to join in and contribute to these languages, and we believe
that such an endeavour should start with evaluating current state of
the art, such that we can make sure our contributions will be relevant
and beneficial. Thus, the first part of this report is a survey of
some of the existing parallel functional programming languages. We
have taken the strategy of implementing some real world example
applications from the financial domain, to study the limitations of
current approaches.

\section{GPU hardware}
Introduce concepts:
 * Memory coalescing
 * Grid of blocks
 * Streaming multiprocessors
 * Host/Device
 * Memory structure

\section{Contributions}
% PLC: Should we have these in the introduction? wouldn't they fit
% better in their respective sections?

% MD: Yes we should, but only as overview/teaser. I think it would be
% easier to read, when it is clear what's to come
\todo{Which kind of problems we have found}

We have found that the lack of nesting in a language such as
Accelerate is too limiting to implement the algorithms that we want,
without sacrificing code clarity. We suggest moving back a step on
ladder and give the programmer more control.

\todo{Something about what we have done to alleviate those problems}

\todo{List our contributions:}

\begin{itemize}

\item A survey comparing of the vector languages CUDA, R, Repa, Accelerate and
  Nikola. The comparison is based on how well they performed with our cases,
  both in terms of expressivity and performance, and the surrounding community
  of developers and users.

\item We found Nikola to be the most promising candidate for useful extensions.

\item We have implemented prototypes of folding, unfolding and nested maps in
  Nikola. While there is yet some way to an acceptable implementation, we
  outline a way to it.

\item We present an alternative way of expressing nested data parallelism, that
  doesn't involve an elaborate code transformation like \cite{nesl}, and
  doesn't impair the compositionality of the language. Like above, we have yet
  to actually test the method in practise.

\end{itemize}

%
%* Example where the Accelerate breaks down, and code does not seem to
%  be written clearly
%
%* An alternative approach to specifying


\section{Report outline}
The remainder of the report is structured as follows. This
introductory chapter is supplemented with two chapters introducing
terminology, one on the financial example problems we are going to use
throughout the report and one on hardware platforms such as GPUs. The
rest of the report after these introductory chapters is divided into
two independent parts. The first part contains a survey of currently
used vector languages and their implementation techniques. The second
part describes our own efforts into \todo{\ldots}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
